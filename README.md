# EduAssistant â€“ Personal Voice Assistant with Memory and Local Integration

**EduAssistant** is a fully personalized voice assistant designed to understand your routine, access your local projects, read your calendar, and interact via voice. Built to run locally on your desktop, it seamlessly connects to your digital life while keeping your data private and under your control.

---

## ğŸ”§ Features

- ğŸ¤ Voice input using OpenAI Whisper API (affordable and accurate for short speech)
- ğŸ§  Interaction powered by GPT-3.5-turbo (low-cost, high-quality language model)
- ğŸ—£ï¸ Voice output using Edge TTS (free, natural-sounding speech synthesis)
- ğŸ“ Smart access to your local files, notes, and personal projects
- ğŸ•“ Basic integration with your personal schedule and routine (via JSON or calendar files)
- ğŸ§¾ Lightweight contextual memory: routines, preferences, and task history


---

## ğŸ–¥ï¸ Tech Stack

- **Python 3.10+**
- `openai` â€“ access to GPT-3.5-turbo and Whisper API
- `edge-tts` â€“ free, natural-sounding text-to-speech
- `faiss` â€“ vector memory engine (for contextual recall, future feature)
- `python-dotenv`, `requests`, `json` â€“ for config and lightweight integration
- CLI interface (initially), designed to expand into desktop or mobile interface

---

## ğŸ“ Project Structure

```bash
edu_assistant/
â”œâ”€â”€ main.py              # Voice/Text interface
â”œâ”€â”€ config.json          # Personal data and API keys
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ vector_store/    # FAISS storage
â”‚   â””â”€â”€ calendar.json    # Calendar data
â”œâ”€â”€ data/
â”‚   â””â”€â”€ projects/        # Your organized projects
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ voice_input.py   # Whisper transcription
â”‚   â”œâ”€â”€ voice_output.py  # Text-to-speech
â”‚   â”œâ”€â”€ gpt_client.py    # OpenAI API calls
â”‚   â”œâ”€â”€ context_loader.py # Context generation
â”‚   â”œâ”€â”€ agenda.py        # Routine and schedule queries
â”‚   â””â”€â”€ actions.py       # Automation scripts

````

---

## ğŸš€ Getting Started

1. Clone the repository:

   ```bash
   git clone git@github.com:eduardo45MP/edu_assistant.git
   cd edu_assistant
   ```

2. Create a virtual environment:

   ```bash
   python3 -m venv venv
   source venv/bin/activate  # or .\venv\Scripts\activate on Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

4. Set up your `config.json` with API keys and personal info.

5. Run the assistant:

   ```bash
   python main.py
   ```

---

## ğŸ“Œ Roadmap (Short-Term)

* [ ] Stable voice input/output
* [ ] Context awareness via local JSON
* [ ] Google Calendar integration
* [ ] Local file/project interaction
* [ ] Desktop interface
* [ ] Optional offline mode (LLM via Ollama or LM Studio)

---

## ğŸ“œ License

MIT â€“ Free to use, modify, and distribute.

---

## âœ¨ Created by Eduardo, powered by Clara (ChatGPT)
